{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taegeonyu/hds5210-2023/blob/main/week14/module56-merging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghfJWm7I-1Ie"
      },
      "source": [
        "# Merging DataFrames Together\n",
        "\n",
        "In this module, we're going to talk about two different types of merging: concatenation and masking"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install awscli"
      ],
      "metadata": {
        "id": "jP7NbDHB--PS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "miRaIflK-1If"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMMtw5dE-1Ig"
      },
      "source": [
        "## Concatenation\n",
        "\n",
        "To \"concatenate\" means to combine things end-to-end.  That is, we're going to merge together multiple data sets in a way that we just keep appending more rows end-on-end.\n",
        "\n",
        "In `https://hds5210-data.s3.amazonaws.com/drinking/` there are a whole list of files that we want to merge together into a single data frame.  They all have the same format, but the are from different cities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOSx6kgh-1Ig"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "# *** WARNING ***\n",
        "# Do not run this code on your local machine if you have the AWS CLI already configured\n",
        "# It could cause a problem with your existing security credentials\n",
        "# and permantently erase your existing access keys and secrets\n",
        "\n",
        "# If you're curious about what this code does,\n",
        "# it creates a file called ~/.aws/credentials with credentials I've created\n",
        "# that allow you to list files in a particular AWS s3 storage bucket.\n",
        "\n",
        "mkdir -p ~/.aws\n",
        "grep hds5210 ~/.aws/credentials 2>/dev/null || cat >>~/.aws/credentials <<EOF\n",
        "[hds5210]\n",
        "aws_access_key_id = AKIAUXBOKEFK63ZPGD62\n",
        "aws_secret_access_key = ***\n",
        "aws_default_region = us-east-1\n",
        "EOF\n",
        "chmod 644 ~/.aws/credentials\n",
        "cat ~/.aws/credentials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOPntJZ3-1Ig"
      },
      "outputs": [],
      "source": [
        "# Then this one-liner gets a list of the files in a specific storage\n",
        "# bucket subfolder and writes that list of files to a files.txt file.\n",
        "# After you run this code, you should see a file in Google Colab\n",
        "# with this same name.  From there, we'll use Python code to get the files.\n",
        "!aws --profile hds5210 s3 ls s3://hds5210-data/drinking/ >files.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USA7d7V--1Ig"
      },
      "outputs": [],
      "source": [
        "# Here's a function we'll use to read all of the file names from that\n",
        "# text file that the aws command above created.\n",
        "# The command above outputs in a \"human readable\" format that we have to parse\n",
        "# making some assumptions (like file names won't have spaces in them).  It\n",
        "# only works because this specific subfolder doesn't have any files with spaces\n",
        "# in the name.\n",
        "\n",
        "def get_files(listing_file):\n",
        "  files = []\n",
        "\n",
        "  # Open the listing file\n",
        "  with open(listing_file) as f:\n",
        "    for line in f.readlines():\n",
        "      # Split based on space, grab the last item, strip off extra newline\n",
        "      name = line.split(' ')[-1].strip()\n",
        "      # The aws command returns an empty-name file as well for some reason\n",
        "      # So, we'll strip that out\n",
        "      if len(name) > 0:\n",
        "        files.append(name)\n",
        "\n",
        "  # Return the list of files\n",
        "  return files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AiHgecJg-1Ig"
      },
      "outputs": [],
      "source": [
        "files = get_files('files.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Geh00Zzz-1Ig"
      },
      "outputs": [],
      "source": [
        "files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6Ujuxe_-1Ig"
      },
      "outputs": [],
      "source": [
        "len(files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6cWVnum-1Ig"
      },
      "outputs": [],
      "source": [
        "# Then, let's read each of those files into their own df and store that in a list of dfs\n",
        "dataframes = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKUCDJLa-1Ig"
      },
      "outputs": [],
      "source": [
        "for f in files:\n",
        "    df = pd.read_csv('https://hds5210-data.s3.amazonaws.com/drinking/'+f)\n",
        "    print(f'Read {f}')\n",
        "    dataframes.append(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wt5qviqm-1Ig"
      },
      "outputs": [],
      "source": [
        "len(dataframes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jr1dk4Zv-1Ih"
      },
      "outputs": [],
      "source": [
        "type(dataframes[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3UXUy1B-1Ih"
      },
      "outputs": [],
      "source": [
        "dataframes[0].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3k99pymv-1Ih"
      },
      "outputs": [],
      "source": [
        "len(dataframes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_n4i4QI-1Ih"
      },
      "outputs": [],
      "source": [
        "# Then we can concatenate them together with pd.concat\n",
        "drinking = pd.concat(dataframes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7FK8W7p-1Ih"
      },
      "source": [
        "Let's check to make sure the counts match up...\n",
        "\n",
        "Length of combined dataframe == Sum of the length of the individual dataframes?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "latgUbIK-1Ih"
      },
      "outputs": [],
      "source": [
        "len(drinking)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEKR21yM-1Ih"
      },
      "outputs": [],
      "source": [
        "sum([len(x) for x in dataframes])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GaCfS_ZV-1Ih"
      },
      "outputs": [],
      "source": [
        "drinking.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qld6VxMl-1Ih"
      },
      "source": [
        "It's also possible to label the rows as they get concatenated together.  That can be handy if you want to keep track of which input file each row came from."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5IVYZzfN-1Ih"
      },
      "outputs": [],
      "source": [
        "drinking2 = pd.concat(dataframes, keys=files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eG5QYR73-1Ih"
      },
      "outputs": [],
      "source": [
        "drinking2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuikKYL2-1Ih"
      },
      "outputs": [],
      "source": [
        "drinking2.head().reset_index(names=['File','Number'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeaJHeYT-1Ih"
      },
      "outputs": [],
      "source": [
        "drinking2.index.levels[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcSCJs0R-1Ih"
      },
      "source": [
        "## Concatenating Side-by-Side\n",
        "\n",
        "The stacking example above is more common, but it might be interesting to concatenate data side-by-side."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSwPd55W-1Ih"
      },
      "outputs": [],
      "source": [
        "names1=[['Paul','Boal'],['Anny', 'Monroe'],['Eric','Westhus'],['Andy','Slavitt']]\n",
        "names2=[['Paul Boal'],['Anny Monroe'],['Eric Westhus'],[''],['Mario Garza']]\n",
        "n1 = pd.DataFrame(names1, columns=['First','Last'])\n",
        "n2 = pd.DataFrame(names2, columns=['Full Name'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-OrN-kO-1Ih"
      },
      "outputs": [],
      "source": [
        "n1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiWec7OH-1Ih"
      },
      "outputs": [],
      "source": [
        "n2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgjFkvZC-1Ih"
      },
      "outputs": [],
      "source": [
        "pd.concat([n1,n2], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZeeZ6Tg-1Ih"
      },
      "source": [
        "## Masking\n",
        "\n",
        "With \"masking\", we are taking two data sets and overlaying one ontop of the other.  If the first has values, then those will be kept.  If the first has a blank (NaN), then the underlying value from the next data set will be shown."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8VXClsu-1Ih"
      },
      "outputs": [],
      "source": [
        "nppes1 = pd.read_csv('https://hds5210-data.s3.amazonaws.com/nppes1.csv')\n",
        "nppes2 = pd.read_csv('https://hds5210-data.s3.amazonaws.com/nppes2.csv')\n",
        "nppes1.set_index('NPI', inplace=True)\n",
        "nppes2.set_index('NPI', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RzEUZ9Z-1Ii"
      },
      "outputs": [],
      "source": [
        "nppes2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5P6zQ2az-1Ii"
      },
      "outputs": [],
      "source": [
        "nppes1['State'].count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEhWFWRX-1Ii"
      },
      "outputs": [],
      "source": [
        "len(nppes1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nxb2cTxz-1Ii"
      },
      "outputs": [],
      "source": [
        "len(nppes2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ip9cmT5j-1Ii"
      },
      "outputs": [],
      "source": [
        "nppes2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnrE14bg-1Ii"
      },
      "outputs": [],
      "source": [
        "nppes1[pd.isnull(nppes1['State'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjNVck3d-1Ii"
      },
      "outputs": [],
      "source": [
        "combined = nppes1.combine_first(nppes2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gm9whIZk-1Ip"
      },
      "outputs": [],
      "source": [
        "combined['State'].count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVb3aOwM-1Ip"
      },
      "outputs": [],
      "source": [
        "len(nppes1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jh1Howk-1Ip"
      },
      "outputs": [],
      "source": [
        "combined.loc[1225590060]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGkt6ojv-1Ip"
      },
      "outputs": [],
      "source": [
        "nppes1.loc[1225590060]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixIVJln9-1Ip"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeFE83LB-1Ip"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrF5WENy-1Ip"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}